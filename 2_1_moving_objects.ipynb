{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8SAfPuyr8Tx/g+3ZYw6ur",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Koftarik/Data_Processing_and_Machine_Learning/blob/main/2_1_moving_objects.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Необходимо разработать программу, детектирующую движение в видеопотоке. Требуется получить доступ к видеопотоку и получать очередные кадры из него. Необходимо получить зоны движения в видеопотоке и корректно определить тип движения в потоке. Написанная работоспособная программа должна обрабатывать не менее двух кадров в секунду.\n"
      ],
      "metadata": {
        "id": "_7nWy9qNIwfN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2beFxVcWc2K1"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(\"video.mp4\"); #вывод кадров из видео файла\n",
        "#cap = cv2.VideoCapture(0); # видео поток с веб камеры\n",
        "\n",
        "cap.set(3,1280) # установка размера окна\n",
        "cap.set(4,700)\n",
        "\n",
        "ret, frame1 = cap.read()\n",
        "ret, frame2 = cap.read()\n",
        "\n",
        "output_video_path = 'output.avi'\n",
        "output_video_res = (1280, 720)\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "output_movie = cv2.VideoWriter(output_video_path, fourcc, 30.0, output_video_res)\n",
        "\n",
        "while cap.isOpened(): # метод isOpened() выводит статус видеопотока\n",
        "  if (frame1 is None) or (frame2 is None):\n",
        "    break\n",
        "  diff = cv2.absdiff(frame1, frame2) # нахождение разницы двух кадров, которая проявляется лишь при изменении одного из них, т.е. с этого момента наша программа реагирует на любое движение.\n",
        "\n",
        "  gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY) # перевод кадров в черно-белую градацию\n",
        "\n",
        "  blur = cv2.GaussianBlur(gray, (5, 5), 0) # фильтрация лишних контуров\n",
        "\n",
        "  _, thresh = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY) # метод для выделения кромки объекта белым цветом\n",
        "\n",
        "  dilated = cv2.dilate(thresh, None, iterations = 3) # данный метод противоположен методу erosion(), т.е. эрозии объекта, и расширяет выделенную на предыдущем этапе область\n",
        "\n",
        "\n",
        "  сontours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) # нахождение массива контурных точек\n",
        "\n",
        "\n",
        "  for contour in сontours:\n",
        "    (x, y, w, h) = cv2.boundingRect(contour) # преобразование массива из предыдущего этапа в кортеж из четырех координат\n",
        "\n",
        "    # метод contourArea() по заданным contour точкам, здесь кортежу, вычисляет площадь зафиксированного объекта в каждый момент времени, это можно проверить\n",
        "    print(cv2.contourArea(contour))\n",
        "\n",
        "    if cv2.contourArea(contour) < 700: # условие при котором площадь выделенного объекта меньше 700 px\n",
        "      continue\n",
        "    cv2.rectangle(frame1, (x, y), (x+w, y+h), (0, 255, 0), 2) # получение прямоугольника из точек кортежа\n",
        "    cv2.putText(frame1, \"Status: {}\".format(\"Dvigenie\"), (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3, cv2.LINE_AA) # вставляем текст\n",
        "\n",
        "  #cv2.drawContours(frame1, сontours, -1, (0, 255, 0), 2) также можно было просто нарисовать контур объекта\n",
        "\n",
        " # cv2.imshow(\"frame1\", frame1)\n",
        "  frame1 = frame2  #\n",
        "  ret, frame2 = cap.read() #\n",
        "\n",
        "  #if cv2.waitKey(40) == 27:\n",
        "  #  break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MmqN7KGhjlk",
        "outputId": "c3bba801-2fb0-4ffd-95af-159a105f70b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48.5\n",
            "48.0\n",
            "69.0\n",
            "60.0\n",
            "49.0\n",
            "684.0\n",
            "36.0\n",
            "55.0\n",
            "48.5\n",
            "56.0\n",
            "2024.0\n",
            "187.5\n",
            "152.5\n",
            "134.5\n",
            "75.0\n",
            "2682.5\n",
            "1594.5\n",
            "62.5\n",
            "49.0\n",
            "42.0\n",
            "36.0\n",
            "48.5\n",
            "44858.5\n",
            "11.5\n",
            "7.0\n",
            "2.0\n",
            "2.0\n",
            "2.0\n",
            "2.0\n",
            "2.0\n",
            "2110.5\n",
            "2.0\n",
            "5.5\n",
            "31.5\n",
            "27.0\n",
            "2.0\n",
            "42.0\n",
            "48.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def get_background(file_path):\n",
        "  cap = cv2.VideoCapture(file_path)\n",
        "  frame_indices = cap.get(cv2.CAP_PROP_FRAME_COUNT) * np.random.uniform(size=50)\n",
        "  frames = []\n",
        "  for idx in frame_indices:\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
        "  ret, frame = cap.read()\n",
        "  frames.append(frame)\n",
        "  median_frame = np.median(frames, axis=0).astype(np.uint8)\n",
        "  return median_frame\n",
        "\n",
        "cap = cv2.VideoCapture('video.mp4')\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "save = 'video_2.mp4'\n",
        "video_out = cv2.VideoWriter(\n",
        " save,\n",
        " cv2.VideoWriter_fourcc(*'mp4v'), 10,\n",
        " (frame_width, frame_height)\n",
        ")\n",
        "\n",
        "background = get_background('video.mp4')\n",
        "background = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
        "frame_count = 0\n",
        "consecutive_frame = 4\n",
        "\n",
        "while (cap.isOpened()):\n",
        " ret, frame = cap.read()\n",
        " if ret == True:\n",
        "  frame_count += 1\n",
        "  orig_frame = frame.copy()\n",
        "  gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        " if frame_count % consecutive_frame == 0 or frame_count == 1:\n",
        "  frame_diff_list = []\n",
        "  frame_diff = cv2.absdiff(gray, background)\n",
        "  ret, thres = cv2.threshold(frame_diff, 50, 255, cv2.THRESH_BINARY)\n",
        "  dilate_frame = cv2.dilate(thres, None, iterations=2)\n",
        "  frame_diff_list.append(dilate_frame)\n",
        " if len(frame_diff_list) == consecutive_frame:\n",
        "  sum_frames = sum(frame_diff_list)\n",
        "  contours, hierarchy = cv2.findContours(sum_frames, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        " for i, cnt in enumerate(contours):\n",
        "  cv2.drawContours(frame, contours, i, (0, 0, 255), -1)\n",
        " for contour in contours:\n",
        "  if cv2.contourArea(contour) < 500:\n",
        "    continue\n",
        "  (x, y, w, h) = cv2.boundingRect(contour)\n",
        "  cv2.rectangle(orig_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "  cv2_imshow(orig_frame)\n",
        "  video_out.write(orig_frame)\n",
        "else:\n",
        "  break\n",
        "video_out.release()\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "CgNNDL4VmobF",
        "outputId": "b3d246d4-b4af-4ede-8082-76fdfd4c8f7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-a86714654fc0>\"\u001b[0;36m, line \u001b[0;32m55\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from vidstab import VidStab\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import os\n",
        "    import cv2\n",
        "    from vidstab import VidStab, layer_overlay, download_ostrich_video\n",
        "\n",
        "    # Download test video to stabilize\n",
        "    # if not os.path.isfile(\"ostrich.mp4\"):\n",
        "    #     download_ostrich_video(\"ostrich.mp4\")\n",
        "\n",
        "    # инициализируем трекер объектов, стабилизатор и захват потока\n",
        "    object_tracker = cv2.TrackerCSRT_create()\n",
        "    stabilizer = VidStab()\n",
        "    vidcap = cv2.VideoCapture(0)\n",
        "\n",
        "    # инициализируем форму для захвата объекта\n",
        "    object_bounding_box = None\n",
        "\n",
        "    while True:\n",
        "        # читаем фрейм\n",
        "        grabbed_frame, frame = vidcap.read()\n",
        "\n",
        "        # передаем фрейм в стабилизатор\n",
        "        stabilized_frame = stabilizer.stabilize_frame(input_frame=frame, border_size=50, smoothing_window=100)\n",
        "\n",
        "        if stabilized_frame is None:\n",
        "            break\n",
        "\n",
        "        # рисуем прямоугольник на выделенном объекте, если начали трекинг\n",
        "        if object_bounding_box is not None:\n",
        "            success, object_bounding_box = object_tracker.update(stabilized_frame)\n",
        "\n",
        "            if success:\n",
        "                (x, y, w, h) = [int(v) for v in object_bounding_box]\n",
        "                cv2.rectangle(stabilized_frame, (x, y), (x + w, y + h),\n",
        "                              (0, 255, 0), 2)\n",
        "\n",
        "        # выводим фрейм\n",
        "        cv2.imshow('Frame', stabilized_frame)\n",
        "\n",
        "        key = cv2.waitKey(5)\n",
        "\n",
        "        # захватываем фрейм\n",
        "        if stabilized_frame.sum() > 0 and object_bounding_box is None:\n",
        "            object_bounding_box = cv2.selectROI(\"Frame\",\n",
        "                                                stabilized_frame,\n",
        "                                                fromCenter=False,\n",
        "                                                showCrosshair=True)\n",
        "            object_tracker.init(stabilized_frame, object_bounding_box)\n",
        "        elif key == 27:\n",
        "            break\n",
        "\n",
        "    vidcap.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "PNrDq3omo2Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 # импорт модуля cv2\n",
        "\n",
        "cap = cv2.VideoCapture(\"video.mp4\"); #вывод кадров из видео файла\n",
        "#cap = cv2.VideoCapture(0); # видео поток с веб камеры\n",
        "\n",
        "cap.set(3,1280) # установка размера окна\n",
        "cap.set(4,700)\n",
        "\n",
        "ret, frame1 = cap.read()\n",
        "ret, frame2 = cap.read()\n",
        "\n",
        "while cap.isOpened(): # метод isOpened() выводит статус видеопотока\n",
        "\n",
        "  diff = cv2.absdiff(frame1, frame2) # нахождение разницы двух кадров, которая проявляется лишь при изменении одного из них, т.е. с этого момента наша программа реагирует на любое движение.\n",
        "\n",
        "  gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY) # перевод кадров в черно-белую градацию\n",
        "\n",
        "  blur = cv2.GaussianBlur(gray, (5, 5), 0) # фильтрация лишних контуров\n",
        "\n",
        "  _, thresh = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY) # метод для выделения кромки объекта белым цветом\n",
        "\n",
        "  dilated = cv2.dilate(thresh, None, iterations = 3) # данный метод противоположен методу erosion(), т.е. эрозии объекта, и расширяет выделенную на предыдущем этапе область\n",
        "\n",
        "\n",
        "  сontours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) # нахождение массива контурных точек\n",
        "\n",
        "\n",
        "  for contour in сontours:\n",
        "    (x, y, w, h) = cv2.boundingRect(contour) # преобразование массива из предыдущего этапа в кортеж из четырех координат\n",
        "\n",
        "    # метод contourArea() по заданным contour точкам, здесь кортежу, вычисляет площадь зафиксированного объекта в каждый момент времени, это можно проверить\n",
        "    print(cv2.contourArea(contour))\n",
        "\n",
        "    if cv2.contourArea(contour) < 700: # условие при котором площадь выделенного объекта меньше 700 px\n",
        "      continue\n",
        "    cv2.rectangle(frame1, (x, y), (x+w, y+h), (0, 255, 0), 2) # получение прямоугольника из точек кортежа\n",
        "    cv2.putText(frame1, \"Status: {}\".format(\"Dvigenie\"), (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3, cv2.LINE_AA) # вставляем текст\n",
        "\n",
        "  #cv2.drawContours(frame1, сontours, -1, (0, 255, 0), 2) также можно было просто нарисовать контур объекта\n",
        "\n",
        "  cv2.imshow(\"frame1\", frame1)\n",
        "  frame1 = frame2  #\n",
        "  ret, frame2 = cap.read() #\n",
        "\n",
        "  if cv2.waitKey(40) == 27:\n",
        "    break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vTXJIg-GrhCf",
        "outputId": "c0fdca42-2fcd-49e1-f3f0-1f245d8c3916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48.5\n",
            "48.0\n",
            "69.0\n",
            "60.0\n",
            "49.0\n",
            "684.0\n",
            "36.0\n",
            "55.0\n",
            "48.5\n",
            "56.0\n",
            "94.0\n",
            "106.0\n",
            "121.0\n",
            "48.0\n",
            "74.0\n",
            "55.5\n",
            "86.0\n",
            "102.5\n",
            "134.5\n",
            "88.5\n",
            "62.5\n",
            "78.5\n",
            "77.5\n",
            "49.0\n",
            "54327.5\n",
            "2.0\n",
            "2.0\n",
            "2.0\n",
            "2.0\n",
            "16.0\n",
            "2.0\n",
            "2.0\n",
            "57.5\n",
            "19.0\n",
            "539.5\n",
            "25.0\n",
            "1027.5\n",
            "112.5\n",
            "82.5\n",
            "67.5\n",
            "216.0\n",
            "3633.5\n",
            "11.5\n",
            "140.0\n",
            "8.5\n",
            "2.0\n",
            "2.0\n",
            "36.0\n",
            "98.5\n",
            "29890.0\n",
            "27.0\n",
            "4.0\n",
            "2.0\n",
            "2.0\n",
            "2.0\n",
            "42.0\n",
            "36.0\n",
            "48.0\n",
            "42.0\n",
            "36.0\n",
            "42.0\n",
            "42.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "DisabledFunctionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDisabledFunctionError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-949f73ecba48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0;31m#cv2.drawContours(frame1, сontours, -1, (0, 255, 0), 2) также можно было просто нарисовать контур объекта\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m   \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"frame1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m   \u001b[0mframe1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe2\u001b[0m  \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/_import_hooks/_cv2.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mDisabledFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDisabledFunctionError\u001b[0m: cv2.imshow() is disabled in Colab, because it causes Jupyter sessions\nto crash; see https://github.com/jupyter/notebook/issues/3935.\nAs a substitution, consider using\n  from google.colab.patches import cv2_imshow\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_snippet",
                "actionText": "Search Snippets for cv2.imshow",
                "snippetFilter": "cv2.imshow"
              }
            ]
          }
        }
      ]
    }
  ]
}
